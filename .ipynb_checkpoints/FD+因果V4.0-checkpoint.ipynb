{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a0d3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pgmpy.base import DAG\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rpy2.robjects import r, pandas2ri \n",
    "pandas2ri.activate()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import plotly\n",
    "from plotly.offline import init_notebook_mode,iplot\n",
    "init_notebook_mode(connected=True) \n",
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f21fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rpy2.robjects.functions.SignatureTranslatedFunction object at 0x000002210F72B780> [RTYPES.CLOSXP]\n",
       "R classes: ('function',)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robjects.r(\"\"\"\n",
    "    data_tofactor<-function(data){\n",
    "\n",
    "        datacols = names(data)\n",
    "       for (i in 1:ncol(data)) {\n",
    "          data[,datacols[i]] <- factor(data[,datacols[i]])\n",
    "        }\n",
    "    return(data)\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "#R结构\n",
    "robjects.r(\"\"\"\n",
    "        \n",
    "        r_sturct_study<-function(self_r_data,bl,hos_id,method){\n",
    "        \n",
    "            library(bnlearn)\n",
    "            \n",
    "            self_r_data = self_r_data[self_r_data[\"hospitalid\"]==hos_id,-1]\n",
    "            \n",
    "            train_size = ceiling(length(self_r_data[,1])*0.7)\n",
    "            \n",
    "            train_data=self_r_data[1:train_size,]\n",
    "            \n",
    "\n",
    "            dag = hc(train_data,score = method,blacklist = bl)\n",
    "            \n",
    "            arcs = arc.strength(dag,self_r_data)\n",
    "\n",
    "            return(arcs)\n",
    "        }\n",
    "\"\"\")\n",
    "\n",
    "#R结构\n",
    "robjects.r(\"\"\"\n",
    "        \n",
    "        r_sturct_study_wl<-function(self_r_data,bl,wl,hos_id,method){\n",
    "        \n",
    "            library(bnlearn)\n",
    "            \n",
    "            self_r_data = self_r_data[self_r_data[\"hospitalid\"]==hos_id,-1]\n",
    "            \n",
    "            train_size = ceiling(length(self_r_data[,1])*0.7)\n",
    "            \n",
    "            train_data=self_r_data[1:train_size,]\n",
    "            \n",
    "\n",
    "            dag = hc(train_data,score = method,whitelist=wl,blacklist = bl)\n",
    "            \n",
    "            arcs = arc.strength(dag,self_r_data)\n",
    "            \n",
    "            return(arcs)\n",
    "        }\n",
    "\"\"\")\n",
    "\n",
    "#定义个一个用来预测的R语言的函数\n",
    "robjects.r(\"\"\"\n",
    "    predict_label<-function(r_dag,self_r_data,hos_id){\n",
    "        library(bnlearn)\n",
    "        \n",
    "        model = model2network(r_dag)\n",
    "        \n",
    "        self_r_data = self_r_data[self_r_data[\"hospitalid\"]==hos_id,-1]\n",
    "            \n",
    "        train_size = ceiling(length(self_r_data[,1])*0.7)\n",
    "            \n",
    "        \n",
    "        \n",
    "        train_data=self_r_data[1:train_size,nodes(model)]\n",
    "        \n",
    "        test_data = self_r_data[(train_size+1):nrow(self_r_data),nodes(model)]\n",
    "    \n",
    "        training_model = bn.fit(model,train_data)\n",
    "        \n",
    "        predicted = predict(training_model, node = \"label\", data = test_data)\n",
    "        \n",
    "        y_true = test_data[,\"label\"]\n",
    "        \n",
    "        out <- c(predicted ,y_true)\n",
    "        \n",
    "        return(out)\n",
    "    }\n",
    "\"\"\")\n",
    "robjects.r(\"\"\"\n",
    "    dag_score<-function(dag,self_r_data,score,hos_id){\n",
    "    \n",
    "    model = model2network(dag)\n",
    "    \n",
    "    self_r_data = self_r_data[self_r_data[\"hospitalid\"]==hos_id,-1]\n",
    "            \n",
    "    train_size = ceiling(length(self_r_data[,1])*0.7)\n",
    "            \n",
    "    train_data=self_r_data[1:train_size,nodes(model)]\n",
    "   \n",
    "    scr = score(model, train_data, type =score)\n",
    "    \n",
    "    return(scr)\n",
    "    }\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a80afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_to_rdag(dag):\n",
    "    #将python的DAG()转化为R语言\n",
    "    rdag_str = \"\"\n",
    "    for node in dag.nodes():\n",
    "        tmp_str = \"[\"+node\n",
    "        if dag.get_parents(node)!=[]:\n",
    "            tmp_str = tmp_str+\"|\"\n",
    "            index = len\n",
    "            for i in range(len(dag.get_parents(node))):\n",
    "                if i == len(dag.get_parents(node))-1:\n",
    "                    tmp_str+=dag.get_parents(node)[i]\n",
    "                else:\n",
    "                    tmp_str+=dag.get_parents(node)[i]+\":\"\n",
    "\n",
    "\n",
    "        tmp_str+=\"]\"\n",
    "        rdag_str += tmp_str\n",
    "    return rdag_str\n",
    "def martix_list(edges_strength):\n",
    "    #将矩阵图信息转换为from-to-val形式\n",
    "    edges_list = []\n",
    "    for from_node in feature:\n",
    "        for to_node in feature:\n",
    "            val = edges_strength.loc[from_node,to_node]\n",
    "            if val!=0:\n",
    "                edges_list.append([from_node,to_node,val])\n",
    "    edges_list = pd.DataFrame(edges_list,columns=[\"from\",\"to\",\"val\"]).sort_values(by=\"val\")\n",
    "    return edges_list\n",
    "def list_to_martix(edges_list):\n",
    "    #将from-to-val形式转换为矩阵图形式\n",
    "    edges_strength = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int8)\n",
    "    for i in range(len(dag_list)):\n",
    "        from_node = edges_list[\"from\"][i]\n",
    "        to_node = edges_list[\"to\"][i]\n",
    "        val = edges_list[\"strength\"][i]\n",
    "        edges_strength.loc[from_node,to_node]=val\n",
    "    edges_matrix = edges_strength.round(2)\n",
    "    return edges_martix\n",
    "def net_score(ed,data,hos_id,scr):\n",
    "    ##转换为R字符串\n",
    "    r_dag = py_to_rdag(ed)\n",
    "    ##预测\n",
    "    r_y = robjects.r['predict_label'](r_dag,data,hos_id)-1\n",
    "    for i in range(len(r_y)):\n",
    "        if r_y[i]<0:\n",
    "            r_y[i]=0\n",
    "        elif r_y[i]>1:\n",
    "            r_y[i]=1\n",
    "\n",
    "    split_size = int(len(r_y)*0.5) \n",
    "    \n",
    "    y_pred = r_y[:split_size]\n",
    "    \n",
    "    y_true = r_y[split_size:]\n",
    "    \n",
    "    acc = accuracy_score(y_true,y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true,y_pred)\n",
    "    f1 = f1_score(y_true,y_pred)\n",
    "    \n",
    "    dag_scr = robjects.r[\"dag_score\"](r_dag,r_DB,scr,hos_id)[0]\n",
    "    \n",
    "    return acc,recall,auc,f1,dag_scr\n",
    "def del_edges():\n",
    "    pass\n",
    "def to_info_martix(hos_id):\n",
    "    data = DB[DB[\"hospitalid\"]==hos_id]\n",
    "    info_martix  =  pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "    for col in data.columns:\n",
    "        for index in data.columns:\n",
    "            if col==index:\n",
    "                info_martix.loc[index,col]=0\n",
    "            else:\n",
    "                info = mutual_info_score(data.loc[:,index],data.loc[:,col])\n",
    "                info_martix.loc[index,col]=info\n",
    "    return info_martix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c45f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FD_client():\n",
    "    def __init__(self,cid,expert_bl):\n",
    "        self.cid = cid\n",
    "        self.score = {\n",
    "            \"acc\":[],\n",
    "            \"recall\":[],\n",
    "            \"auc\":[],\n",
    "            \"f1\":[],\n",
    "            \"score\":[]}\n",
    "        ##记录边的强度\n",
    "        self.edges_strength = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "        ##记录边的频数\n",
    "        self.edges_num = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "        \n",
    "        self.info_list = martix_list(to_info_martix(self.cid).round(4))\n",
    "        #构建互信息黑名单\n",
    "        info_bl = []\n",
    "        for i in range(len(self.info_list)):\n",
    "            if self.info_list[\"val\"][i]<0.01:\n",
    "                info_bl.append([self.info_list[\"from\"][i],self.info_list[\"to\"][i]])\n",
    "                \n",
    "        bl = info_bl+expert_bl\n",
    "        bl = pd.DataFrame(bl,columns=[\"from\",\"to\"])\n",
    "        \n",
    "        bl = robjects.conversion.py2rpy(bl)\n",
    "        self.bl = bl\n",
    "    def init_dag(self,method):\n",
    "        ##第一轮初始化训练\n",
    "        \n",
    "        edges  = robjects.r['r_sturct_study'](r_DB,self.bl,self.cid,method)\n",
    "        \n",
    "        edges_list  = robjects.pandas2ri.rpy2py_dataframe(edges).sort_values(by=\"strength\",ascending=False)\n",
    "        \n",
    "        dag = DAG()\n",
    "        #强度列表 => DAG()\n",
    "        self.edges_strength.iloc[:,:]=0\n",
    "        self.edges_num.iloc[:,:]=0\n",
    "        for i in range(len(edges_list )):\n",
    "            #强度列表转为DAG()\n",
    "            dag.add_edge(edges_list [\"from\"][i],edges_list [\"to\"][i])\n",
    "            #强度记录\n",
    "            self.edges_strength.loc[[edges_list [\"from\"][i]],[edges_list [\"to\"][i]]]=edges_list [\"strength\"][i]\n",
    "            #频数记录\n",
    "            self.edges_num.loc[[edges_list [\"from\"][i]],[edges_list [\"to\"][i]]]=1\n",
    "\n",
    "        self.dag = dag\n",
    "        #进行性能计算\n",
    "        \n",
    "        dag_score= net_score(self.dag,r_DB,self.cid,method)\n",
    "        \n",
    "        self.score[\"acc\"].append(dag_score[0])\n",
    "        self.score[\"recall\"].append(dag_score[1])\n",
    "        self.score[\"auc\"].append(dag_score[2])\n",
    "        self.score[\"f1\"].append(dag_score[3])\n",
    "        self.score[\"score\"].append(dag_score[4])\n",
    "        \n",
    "        return \n",
    "    def update(self,wl,method):\n",
    "        ##进行更新,基于网络评分的回退筛选机制\n",
    "        ##基于wl学习的网络生成DAG图进行判断\n",
    "        dag = DAG()\n",
    "        \n",
    "        edges  = robjects.r['r_sturct_study_wl'](r_DB,self.bl,wl,self.cid,method)\n",
    "        \n",
    "        edges_list = robjects.pandas2ri.rpy2py_dataframe(edges).sort_values(by=\"strength\",ascending=False)\n",
    "        \n",
    "        #将强度列表转换为DAG()\n",
    "        for i in range(len(edges_list)):\n",
    "            dag.add_edge(edges_list[\"from\"][i],edges_list[\"to\"][i])\n",
    "        \n",
    "        dag_score= net_score(dag,r_DB,self.cid,method)\n",
    "        \n",
    "        \"\"\"判断是否加入白名单\"\"\"\n",
    "        if 1==1:\n",
    "            self.edges_strength.iloc[:,:]=0\n",
    "            self.edges_num.iloc[:,:]=0\n",
    "            #更新边强度什么的\n",
    "            self.dag = dag\n",
    "            for i in range(len(edges_list)):\n",
    "                self.edges_strength.loc[[edges_list[\"from\"][i]],[edges_list [\"to\"][i]]]=edges_list [\"strength\"][i]\n",
    "                self.edges_num.loc[[edges_list[\"from\"][i]],[edges_list [\"to\"][i]]]=1\n",
    "\n",
    "                dag.add_edge(edges_list [\"from\"][i],edges_list [\"to\"][i])\n",
    "            #将只与label有关的节点加入数据\n",
    "            \n",
    "            for i in range(len(edges_list)):\n",
    "                \n",
    "                self.edges_strength.loc[[edges_list[\"from\"][i]],[edges_list [\"to\"][i]]]=edges_list [\"strength\"][i]\n",
    "                self.edges_num.loc[[edges_list[\"from\"][i]],[edges_list [\"to\"][i]]]=1\n",
    "                dag.add_edge(edges_list [\"from\"][i],edges_list [\"to\"][i])\n",
    "        else:\n",
    "            #则将重复记录旧分数，因为网络没有变所以不更改\n",
    "            dag_score = [\n",
    "                self.score[\"acc\"][-1],\n",
    "                self.score[\"recall\"][-1],\n",
    "                self.score[\"auc\"][-1],\n",
    "                self.score[\"f1\"][-1],\n",
    "                self.score[\"score\"][-1],\n",
    "            ]\n",
    "        \n",
    "        self.score[\"acc\"].append(dag_score[0])\n",
    "        self.score[\"recall\"].append(dag_score[1])\n",
    "        self.score[\"auc\"].append(dag_score[2])\n",
    "        self.score[\"f1\"].append(dag_score[3])\n",
    "        self.score[\"score\"].append(dag_score[4])\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b7d82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FD_sever():\n",
    "    def __init__(self,method,learning_rate):\n",
    "        self.method = method\n",
    "        self.learning_rate = learning_rate\n",
    "        self.round_num=+1\n",
    "        self.score = {\n",
    "            \"acc\":[],\n",
    "            \"recall\":[],\n",
    "            \"auc\":[],\n",
    "            \"f1\":[],\n",
    "            \"score\":[]}\n",
    "        \n",
    "        \n",
    "    ##在这里定义融合策略\n",
    "    def num_method(self,edges_num):\n",
    "        #转换为二维的dataframe格式\n",
    "        edges_list = martix_list(edges_num)\n",
    "        wl = []\n",
    "        print(edges_list)\n",
    "        for i in range(len(edges_list)):\n",
    "            if edges_list[\"val\"][i] >=7:\n",
    "                n1=edges_list.iloc[i,0]\n",
    "                n2=edges_list.iloc[i,1]\n",
    "                wl.append((n1,n2))\n",
    "        return wl\n",
    "    def select_wl(self,edges_strength,edges_num,weight,mehtod):\n",
    "        learing_rate = self.round_num*self.learning_rate\n",
    "        self.round_num+=1\n",
    "        \"\"\"\n",
    "        method:\n",
    "            0:频数\n",
    "            1:强度\n",
    "            2:基于分数和网络频数的剪枝策略\n",
    "            3:强度+频数\n",
    "            4:与label有关的强度集筛选\n",
    "        learing_rare:\n",
    "            学习步长-每次传递多少条边\n",
    "        weught:\n",
    "            数据量的权重\n",
    "        return 一个转换\n",
    "        \"\"\"\n",
    "        fuse_DAG = DAG()\n",
    "        \n",
    "        for col in feature:\n",
    "            for idx in feature:\n",
    "                #根据频数判断，如果有相同方向的则取频数较大的边\n",
    "                if edges_num[col][idx]!=0 and edges_num[col][idx]<=edges_num[idx][col]:\n",
    "                    print(col,idx)\n",
    "                    edges_num.loc[idx,col] = 0\n",
    "                    edges_strength.loc[idx,col]=0\n",
    "                    \n",
    "        if mehtod==0:\n",
    "            #选取一定长度的\n",
    "            wl = self.num_method(edges_num)\n",
    "        elif method==1:\n",
    "            pass\n",
    "        elif method==2:\n",
    "            pass\n",
    "        elif method==3:\n",
    "            pass\n",
    "        elif methid==4:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"融合策略码错误\")\n",
    "        #f返回结果\n",
    "        \n",
    "        fuse_DAG.add_edges_from(wl)\n",
    "        wl=pd.DataFrame(wl,columns=[\"from\",\"to\"])\n",
    "        return fuse_DAG,wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee0da6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#定义计算熵的函数\n",
    "def ent(data):\n",
    "    prob1 = pd.value_counts(data) / len(data)\n",
    "    return sum(np.log2(prob1) * prob1 * (-1))\n",
    " \n",
    " \n",
    "def gain(data,str1,str2):\n",
    "    e1 = data.groupby(str1).apply(lambda x:ent(x[str2]))\n",
    "    p1 = pd.value_counts(data[str1]) / len(data[str1])\n",
    "    e2 = sum(e1 * p1)\n",
    "    return ent(data[str2]) - e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6639fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB= pd.read_csv(\"c:data/site_16topaucoutlinePmmImpData_dis.csv\").drop(columns=\"Unnamed: 0\",axis = 1)\n",
    "feature_list = DB.drop(columns=\"hospitalid\",axis=1)\n",
    "DB=DB.sample(frac=1,random_state=11).reset_index(drop=True)\n",
    "r_DB=robjects.pandas2ri.py2rpy(DB)\n",
    "r_DB =robjects.r['data_tofactor'](r_DB)\n",
    "\n",
    "hos_id = [420,142,122,435,390,227,144,140,396,141]\n",
    "hos_id = np.sort(hos_id)\n",
    "# hos_id = list(set(DB_1.iloc[:,0]))\n",
    "hos_id=np.sort(hos_id)\n",
    "feature = DB.drop(columns=\"hospitalid\",axis=1).columns\n",
    "  #设置黑名单\n",
    "bl =[]\n",
    "for i in feature_list:\n",
    "    bl.append([\"label\",i])\n",
    "    bl.append([i,\"sex\"])\n",
    "    bl.append([i,\"race\"])\n",
    "    bl.append([i,\"bmi\"])\n",
    "\n",
    "\n",
    "\n",
    "#初始化客户端\n",
    "scr = \"k2\"\n",
    "client_num = len(hos_id)\n",
    "clients = []\n",
    "for i in range(client_num):\n",
    "    clients.append(FD_client(hos_id[i],bl))\n",
    "    clients[i].init_dag(scr)\n",
    "    \n",
    "#初始化中心\n",
    "learning_rate = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "649291d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respiration heartrate\n",
      "LAB2 LAB42\n",
      "LAB3 LAB38\n",
      "LAB3 COM11\n",
      "LAB4 LAB14\n",
      "LAB4 LAB18\n",
      "LAB4 LAB25\n",
      "LAB7 LAB11\n",
      "LAB10 LAB12\n",
      "LAB10 LAB18\n",
      "LAB10 LAB39\n",
      "LAB10 LAB59\n",
      "LAB12 LAB15\n",
      "LAB12 LAB56\n",
      "LAB12 PRO8\n",
      "LAB14 LAB20\n",
      "LAB15 LAB34\n",
      "LAB16 LAB2\n",
      "LAB18 LAB50\n",
      "LAB19 age\n",
      "LAB19 LAB7\n",
      "LAB19 LAB8\n",
      "LAB19 COM5\n",
      "LAB23 LAB57\n",
      "LAB24 LAB2\n",
      "LAB24 LAB3\n",
      "LAB24 LAB39\n",
      "LAB24 LAB53\n",
      "LAB25 LAB14\n",
      "LAB27 LAB5\n",
      "LAB35 LAB57\n",
      "LAB36 LAB23\n",
      "LAB38 COM11\n",
      "LAB39 LAB2\n",
      "LAB43 LAB6\n",
      "LAB44 LAB56\n",
      "LAB46 LAB47\n",
      "LAB47 LAB56\n",
      "LAB48 LAB6\n",
      "LAB53 LAB54\n",
      "LAB54 LAB55\n",
      "LAB57 LAB18\n",
      "LAB57 COM9\n",
      "LAB59 LAB2\n",
      "LAB59 LAB12\n",
      "LAB59 LAB24\n",
      "COM1 age\n",
      "COM2 COM8\n",
      "COM3 COM7\n",
      "COM3 COM11\n",
      "COM4 COM10\n",
      "COM4 PRO2\n",
      "COM4 PRO9\n",
      "COM5 COM1\n",
      "COM7 COM1\n",
      "COM7 COM5\n",
      "COM7 COM8\n",
      "COM7 COM10\n",
      "COM8 COM11\n",
      "COM10 COM1\n",
      "COM10 COM3\n",
      "COM11 COM5\n",
      "COM11 COM10\n",
      "PRO3 COM8\n",
      "PRO3 PRO1\n",
      "PRO3 PRO2\n",
      "PRO3 PRO4\n",
      "PRO3 PRO6\n",
      "PRO3 PRO7\n",
      "PRO3 PRO8\n",
      "PRO4 COM8\n",
      "PRO4 PRO7\n",
      "PRO7 PRO8\n",
      "PRO8 COM8\n",
      "PRO8 PRO2\n",
      "PRO9 PRO2\n",
      "PRO9 PRO3\n",
      "PRO9 PRO8\n",
      "      from     to  val\n",
      "0      sex   LAB7    1\n",
      "142   COM4   LAB5    1\n",
      "143   COM4   COM8    1\n",
      "146   COM4   PRO9    1\n",
      "148   COM6  label    1\n",
      "..     ...    ...  ...\n",
      "110  LAB48  LAB46   10\n",
      "93   LAB44  LAB43   10\n",
      "163   COM8  label   10\n",
      "1      sex  LAB43   10\n",
      "85   LAB39  LAB42   10\n",
      "\n",
      "[246 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in build.whitelist(whitelist, nodes = names(x), data = x, algo = heuristic,  : \n",
      "  this whitelist does not allow an acyclic graph.\n",
      "\n",
      "R[write to console]: In addition: \n",
      "R[write to console]: There were 50 or more warnings (use warnings() to see the first 50)\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respiration heartrate\n",
      "LAB2 LAB16\n",
      "LAB2 LAB39\n",
      "LAB3 LAB38\n",
      "LAB3 COM11\n",
      "LAB4 LAB18\n",
      "LAB4 LAB25\n",
      "LAB7 LAB11\n",
      "LAB10 LAB12\n",
      "LAB10 LAB44\n",
      "LAB12 LAB15\n",
      "LAB12 LAB56\n",
      "LAB14 LAB4\n",
      "LAB14 LAB20\n",
      "LAB15 LAB14\n",
      "LAB18 LAB50\n",
      "LAB18 LAB57\n",
      "LAB19 age\n",
      "LAB19 LAB8\n",
      "LAB23 LAB36\n",
      "LAB24 LAB19\n",
      "LAB24 LAB53\n",
      "LAB25 LAB14\n",
      "LAB27 LAB5\n",
      "LAB34 LAB14\n",
      "LAB34 LAB15\n",
      "LAB35 LAB36\n",
      "LAB35 LAB57\n",
      "LAB38 COM11\n",
      "LAB43 LAB6\n",
      "LAB44 LAB56\n",
      "LAB46 LAB47\n",
      "LAB47 LAB56\n",
      "LAB57 LAB23\n",
      "LAB57 COM9\n",
      "LAB59 LAB10\n",
      "COM1 COM5\n",
      "COM2 COM8\n",
      "COM3 COM10\n",
      "COM4 COM10\n",
      "COM4 PRO2\n",
      "COM5 LAB19\n",
      "COM6 COM8\n",
      "COM7 COM11\n",
      "COM8 COM7\n",
      "COM8 COM11\n",
      "COM10 COM1\n",
      "COM11 COM5\n",
      "COM11 COM10\n",
      "PRO2 PRO3\n",
      "PRO2 PRO8\n",
      "PRO2 PRO9\n",
      "PRO3 COM8\n",
      "PRO3 PRO4\n",
      "PRO3 PRO6\n",
      "PRO3 PRO7\n",
      "PRO4 PRO7\n",
      "PRO8 PRO3\n",
      "PRO9 PRO3\n",
      "PRO9 PRO8\n",
      "      from     to  val\n",
      "73   LAB34   LAB4    1\n",
      "72   LAB34    age    1\n",
      "71   LAB27  COM10    1\n",
      "116  LAB59   LAB2    1\n",
      "167  COM10   COM5    1\n",
      "..     ...    ...  ...\n",
      "118  LAB59  LAB12   10\n",
      "40   LAB12   PRO8   10\n",
      "79   LAB34  LAB48   10\n",
      "205   PRO4   PRO9   10\n",
      "0      sex  LAB43   10\n",
      "\n",
      "[240 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in build.whitelist(whitelist, nodes = names(x), data = x, algo = heuristic,  : \n  this whitelist does not allow an acyclic graph.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#更新\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(client_num):\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwl_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mFD_client.update\u001b[1;34m(self, wl, method)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m,wl,method):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m##进行更新,基于网络评分的回退筛选机制\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m##基于wl学习的网络生成DAG图进行判断\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     dag \u001b[38;5;241m=\u001b[39m DAG()\n\u001b[1;32m---> 62\u001b[0m     edges  \u001b[38;5;241m=\u001b[39m \u001b[43mrobjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr_sturct_study_wl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_DB\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwl\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     edges_list \u001b[38;5;241m=\u001b[39m robjects\u001b[38;5;241m.\u001b[39mpandas2ri\u001b[38;5;241m.\u001b[39mrpy2py_dataframe(edges)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrength\u001b[39m\u001b[38;5;124m\"\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m#将强度列表转换为DAG()\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\robjects\\functions.py:203\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m         v \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(k)\n\u001b[0;32m    202\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28msuper\u001b[39m(SignatureTranslatedFunction, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\robjects\\functions.py:126\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[1;32m--> 126\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(Function, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    127\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cdata_to_rinterface(cdata)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\rinterface.py:815\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m     res \u001b[38;5;241m=\u001b[39m rmemory\u001b[38;5;241m.\u001b[39mprotect(\n\u001b[0;32m    809\u001b[0m         openrlib\u001b[38;5;241m.\u001b[39mrlib\u001b[38;5;241m.\u001b[39mR_tryEval(\n\u001b[0;32m    810\u001b[0m             call_r,\n\u001b[0;32m    811\u001b[0m             call_context\u001b[38;5;241m.\u001b[39m__sexp__\u001b[38;5;241m.\u001b[39m_cdata,\n\u001b[0;32m    812\u001b[0m             error_occured)\n\u001b[0;32m    813\u001b[0m     )\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 815\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: Error in build.whitelist(whitelist, nodes = names(x), data = x, algo = heuristic,  : \n  this whitelist does not allow an acyclic graph.\n"
     ]
    }
   ],
   "source": [
    "#学习步长和学习轮次\n",
    "fuse_dag_list = []\n",
    "sever = FD_sever(scr,learning_rate)\n",
    "random_num =10\n",
    "for i in range(random_num):\n",
    "    #初始化融合强度矩阵，融合边强度，白名单列表\n",
    "    fuse_edges_num = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "    fuse_edges_strength = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "    wl =[]\n",
    "    fuse_dag = DAG()\n",
    "    #汇集\n",
    "    for k in range(client_num):\n",
    "        fuse_edges_num+=clients[k].edges_num\n",
    "        fuse_edges_strength+=clients[k].edges_strength\n",
    "    \n",
    "    fuse_dag,wl=sever.select_wl(fuse_edges_strength,fuse_edges_num,1,0)\n",
    "   #看融合不去除边的网络在数据集上的性能\n",
    "    fuse_dag_list.append(fuse_dag)\n",
    "    #转换白名单\n",
    "    wl_r =robjects.conversion.py2rpy(wl)\n",
    "    #更新\n",
    "    for k in range(client_num):\n",
    "        clients[k].update(wl_r,scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1cf8a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.7967698519515478, 0.7981157469717362],\n",
       " 'recall': [0.7208121827411168, 0.7258883248730964],\n",
       " 'auc': [0.7724940034584705, 0.7750320745244602],\n",
       " 'f1': [0.6528735632183909, 0.6559633027522935],\n",
       " 'score': [-63230.52014817562, -63839.54471812979]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5634b536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COM4 -> LAB5 ;\n",
      "COM7 -> LAB36 ;\n",
      "COM7 -> COM1 ;\n",
      "COM8 -> LAB5 ;\n",
      "COM8 -> LAB24 ;\n",
      "LAB24 -> LAB2 ;\n",
      "LAB24 -> LAB39 ;\n",
      "LAB59 -> PRO1 ;\n",
      "COM3 -> COM7 ;\n",
      "PRO6 -> PRO1 ;\n",
      "PRO7 -> COM3 ;\n",
      "PRO7 -> PRO1 ;\n",
      "PRO8 -> LAB53 ;\n",
      "PRO9 -> COM5 ;\n",
      "PRO3 -> LAB14 ;\n",
      "LAB14 -> COM7 ;\n",
      "LAB42 -> LAB27 ;\n",
      "PRO4 -> PRO9 ;\n",
      "PRO4 -> LAB16 ;\n",
      "bmi -> PRO2 ;\n",
      "LAB3 -> LAB59 ;\n",
      "LAB10 -> LAB2 ;\n",
      "LAB19 -> LAB11 ;\n",
      "LAB19 -> label ;\n",
      "LAB19 -> LAB7 ;\n",
      "LAB12 -> PRO8 ;\n",
      "race -> LAB53 ;\n",
      "LAB34 -> LAB48 ;\n",
      "COM9 -> LAB56 ;\n"
     ]
    }
   ],
   "source": [
    "for i in fuse_dag_list[0].edges:\n",
    "    print(i[0],\"->\",i[1],\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db9492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
