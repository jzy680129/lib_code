{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b452a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import BicScore\n",
    "from pgmpy.base import DAG\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pgmpy.base import DAG\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import globalenv\n",
    "from rpy2.robjects.packages import importr\n",
    "from pgmpy.estimators import K2Score\n",
    "from rpy2.robjects import conversion, default_converter, pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "import rpy2.robjects as ro\n",
    "from pgmpy.estimators import ExpectationMaximization as EM\n",
    "from pgmpy.estimators import BayesianEstimator as BE\n",
    "from pgmpy.estimators import BDeuScore\n",
    "from pgmpy.estimators import BicScore\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b37bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(edges_dag,columns):\n",
    "    #将图转换为矩阵\n",
    "    edges_matrix = pd.DataFrame(np.zeros((len(columns),len(columns))),index = columns,columns=columns).astype(int)\n",
    "    for edges in edges_dag:\n",
    "        edges_matrix.loc[edges[0],edges[1]]+=1\n",
    "    return edges_matrix\n",
    "def to_dag(edges_matrix):\n",
    "    edges_list = []\n",
    "    for index in edges_matrix.index:\n",
    "        for col in edges_matrix.columns:\n",
    "            if edges_matrix.loc[index,col]!=0:\n",
    "                edges_list.append((index,col))\n",
    "            \n",
    "    #将矩阵转换为图\n",
    "    return edges_list\n",
    "# Funtion to evaluate the learned model structures.\n",
    "def get_f1_score(estimated_model, true_model):\n",
    "    nodes = estimated_model.nodes()\n",
    "    est_adj = nx.to_numpy_matrix(\n",
    "        estimated_model.to_undirected(), nodelist=nodes, weight=None\n",
    "    )\n",
    "    true_adj = nx.to_numpy_matrix(\n",
    "        true_model.to_undirected(), nodelist=nodes, weight=None\n",
    "    )\n",
    "\n",
    "    f1 = f1_score(np.ravel(true_adj), np.ravel(est_adj))\n",
    "    print(\"F1-score for the model skeleton: \", f1)    \n",
    "def print_dag(dag):\n",
    "    if dag.has_node(\"label\"):\n",
    "        for edges in dag.get_ancestral_graph(\"label\").edges:\n",
    "            print(edges[0],\"->\",edges[1],\";\")\n",
    "    else:\n",
    "        for edges in dag.edges:\n",
    "            print(edges[0],\"->\",edges[1],\";\")\n",
    "def model_auc(prob,y_true):\n",
    "    y_prob = []\n",
    "    num = 0\n",
    "    for i in range(len(prob)):\n",
    "        y_prob.append(prob.iloc[i,y_true[i]])\n",
    "    if y_predic[i]==y_true[i]:\n",
    "        num+=1\n",
    "    fpr, tpr, thresholds = roc_curve(y_true,y_predic)\n",
    "    \n",
    "    return auc(fpr, tpr)\n",
    "def to_strength_list(edges_strength_martix):\n",
    "    str_list = []\n",
    "    for col in edges_strength_martix.columns:\n",
    "        for idx in edges_strength_matrix.columns:\n",
    "            if edges_strength_matrix[col][idx] < 0:\n",
    "                str_list.append([idx,col,edges_strength_matrix[col][idx]])\n",
    "    return str_list\n",
    "def print_edges(ed):\n",
    "    for i in ed:\n",
    "        print(i[0],\"->\",i[1],\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174fa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class client():\n",
    "    \"\"\"\n",
    "    只改动模型训练部分\n",
    "    black和whitelist 的名单修改\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,data,cid,strength):\n",
    "        #black 用R语言的存储方式存储·\n",
    "        self.data = data\n",
    "        self.cid = cid\n",
    "        #初始化创建一个空的图\n",
    "        self.model = DAG()\n",
    "        self.edges_strength =  strength\n",
    "        \n",
    "    def get_model(self):\n",
    "        #获得本地客户端网络结构\n",
    "        return self.model\n",
    "    def fit(self):\n",
    "        #记录最好的模型\n",
    "        # 代改动部分        \n",
    "        \n",
    "        self_r_data = ro.conversion.py2rpy(self.data)\n",
    "        globalenv['self_r_data'] = self_r_data\n",
    "        r_script=\"\"\"\n",
    "        library(bnlearn)\n",
    "        for(j in 1:ncol(self_r_data)){\n",
    "            self_r_data[,j] <-as.factor(self_r_data[,j])\n",
    "        }\n",
    "        \n",
    "        dag = hc(self_r_data,score = sc,blacklist = bl_r)\n",
    "        arcs = arc.strength(dag,self_r_data)\n",
    "        \n",
    "        \"\"\"\n",
    "        edges = r(r_script)\n",
    "        self.arc_strength_list = pd.DataFrame(edges)\n",
    "        self.model_edges = edges\n",
    "        #创建新的模型，并添加结果\n",
    "        self.model = DAG()\n",
    "        for i in range(len(edges[\"from\"])):\n",
    "            #汇集频数\n",
    "            self.model.add_edge(edges[\"from\"][i],edges[\"to\"][i])\n",
    "          \n",
    "            \n",
    "#             #汇集强度\n",
    "            self.edges_strength.loc[[edges[\"from\"][i]],[edges[\"to\"][i]]]=edges[\"strength\"][i]\n",
    "        \n",
    "        return 1\n",
    "    def set_parment(self):\n",
    "        #从服务器中心get到网络结构\n",
    "        #初始化model\n",
    "        model.edges\n",
    "    \n",
    "        return \n",
    "    def update_model(self,fuse_dag):\n",
    "        #代改动部分，每次也是创建一个新的贝叶斯网络实例进行白名单结构学习，并返回边模型，最好还是保持pgmpy的形式\n",
    "        \n",
    "        \n",
    "        self.model = DAG()\n",
    "        #设置白名单\n",
    "        white_list = fuse_dag.edges()\n",
    "        wl = []\n",
    "        for edge in white_list:\n",
    "            wl.append([edge[0],edge[1]])\n",
    "        \n",
    "        wl = pd.DataFrame(wl,columns=[\"from\",\"to\"])\n",
    "        wl_r =ro.conversion.py2rpy(wl)\n",
    "        globalenv['wl_r'] = wl_r\n",
    "        self_r_data = ro.conversion.py2rpy(self.data)\n",
    "        globalenv['self_r_data'] = self.data\n",
    "        r_script=\"\"\"\n",
    "        library(bnlearn)\n",
    "       \n",
    "        for(j in 1:ncol(self_r_data)){\n",
    "            self_r_data[,j] <-as.factor(self_r_data[,j])\n",
    "        }\n",
    "        \n",
    "        dag = hc(self_r_data,score = sc,blacklist = bl_r,whitelist = wl_r)\n",
    "        \n",
    "        arcs = arc.strength(dag,self_r_data)\n",
    "        \n",
    "        \"\"\"\n",
    "        edges = r(r_script)\n",
    "        print(edges)\n",
    "        self.model_edges = edges\n",
    "        \n",
    "        for i in range(len(edges[\"from\"])):\n",
    "            self.model.add_edge(edges[\"from\"][i],edges[\"to\"][i])\n",
    "        \n",
    "\n",
    "        \n",
    "class sever():\n",
    "    def __init__(self,fuse_num):\n",
    "        self.fuse_num = fuse_num\n",
    "    def Fd_caculate(self,edges_strength_matrix):\n",
    "        #聚合方法\n",
    "        #聚合的方式改为计算强度的阈值，并返回一个有无环图\n",
    "        \n",
    "        #变为list，并且设置为df格式\n",
    "        arc_ls = pd.DataFrame(to_strength_list(edges_strength_matrix.astype(np.float16)),columns=[\"from\",\"to\",\"strength\"])\n",
    "        #from和to的df格式并按大小排列\n",
    "        arc_ls = arc_ls.sort_values(by=\"strength\",ascending=False)\n",
    "        #1.按照10个选择，但是白名单的列表应该不断的成长，而不是固定的数值\n",
    "        #在每次讲融合DAG加入网络之后，先检验是否有这条边，如果有则跳过\n",
    "    \n",
    "        i = 0\n",
    "        index = 0\n",
    "        while i < 10:\n",
    "           \n",
    "            \n",
    "            arc = (arc_ls.loc[i+index,\"from\"],arc_ls.loc[i+index,\"to\"])\n",
    "            print(arc,arc_ls.loc[i+index,\"strength\"])\n",
    "            if fuseDAG.has_edge(arc[0],arc[1]):\n",
    "                index+=1 \n",
    "            elif fuseDAG.has_edge(arc[1],arc[0]):\n",
    "                index+=1\n",
    "                continue\n",
    "            else:\n",
    "                fuseDAG.add_edge(arc[0],arc[1])\n",
    "                i+=1\n",
    "            \n",
    "            \n",
    "        return  fuseDAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f850553",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DB_1 = pd.read_csv(\"c:data/site_16topaucoutlinePmmImpData_dis.csv\").drop(columns=\"Unnamed: 0\",axis = 1)\n",
    "DB_1[\"label\"].value_counts()\n",
    "DB_1 = DB_1.astype(np.int16)\n",
    "\n",
    "# 数据分割\n",
    "hos_id = [420,142,122,435,390,227,195,243,403,141]\n",
    "client_data = []\n",
    "for hosid in hos_id:\n",
    "    client_data.append(DB_1[DB_1[\"hospitalid\"]==hosid ].iloc[:,:].drop(columns = [\"hospitalid\"],axis = 1))\n",
    "    \n",
    "feature = client_data[0].columns\n",
    "\n",
    "#设置黑名单\n",
    "bl = []\n",
    "for i in feature:\n",
    "    if i ==\"label\":\n",
    "        pass\n",
    "    bl.append([\"label\",i])\n",
    "for i in feature:\n",
    "    if i ==\"age\":\n",
    "        pass\n",
    "    bl.append([i,\"age\"])\n",
    "for i in feature:\n",
    "    if i ==\"sex\":\n",
    "        pass\n",
    "    bl.append([i,\"sex\"])\n",
    "for i in feature:\n",
    "    if i ==\"race\":\n",
    "        pass\n",
    "    bl.append([i,\"race\"])\n",
    "\n",
    "bl = pd.DataFrame(bl,columns=[\"from\",\"to\"])\n",
    "bl_r = ro.conversion.py2rpy(bl)\n",
    "globalenv['bl_r'] = bl_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e16a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算样本量比重\n",
    "D = 19388\n",
    "D_W = []\n",
    "for i in range(10):\n",
    "    D_W.append(len(client_data[i])/D)\n",
    "D_W = np.float16(D_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed9fa618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(ed,DB,cid):\n",
    "    \n",
    "    #cid客户端号，寻找相应的训练数据\n",
    "    auc_score = np.zeros((10,1))\n",
    "    recall = np.zeros((10,1))\n",
    "    acc = np.zeros((10,1))\n",
    "# #    实例化对象\n",
    "#     model= BayesianNetwork()\n",
    "#     #创建边\n",
    "    \n",
    "#     model.add_edges_from(ed)\n",
    "#     #确保数据的每一个都是新的\n",
    "#     f_1 = model.nodes\n",
    "        \n",
    "#     f_2 = DB[cid].columns\n",
    "#     data =DB[cid].copy(deep=True)\n",
    "#     drop_name = []\n",
    "#     for j in f_2:\n",
    "#         if not j in f_1:\n",
    "#             drop_name.append(j)\n",
    "#     data = data.drop(columns = drop_name,axis = 1)\n",
    "    \n",
    "#     #分出训练集\n",
    "#     train_data,test_data = train_test_split(DB[cid],test_size=0.3,random_state=2)\n",
    "#     #训练\n",
    "#     model.fit(train_data,estimator=BE)\n",
    "    \n",
    "    for i in range(len(DB)): \n",
    "        \n",
    "        model_i= BayesianNetwork(ed.edges)\n",
    "        #创建边\n",
    "        data = DB[i]\n",
    "        \n",
    "        f_1 = model_i.nodes\n",
    "        \n",
    "        f_2 = data.columns\n",
    "        #所有mode有的节点\n",
    "        drop_name = []\n",
    "        for j in f_2:\n",
    "            if not j in f_1:\n",
    "                drop_name.append(j)        \n",
    "        data = data.drop(columns = drop_name,axis = 1)\n",
    "        \n",
    "        \n",
    "        #创建离散变量说明\n",
    "        this_dict = []\n",
    "\n",
    "        for key,value in zip(state_names.keys(),state_names.values()):\n",
    "            \n",
    "            if key in f_1:\n",
    "\n",
    "                this_dict.append((key,value))\n",
    "        this_dict = dict(this_dict)\n",
    "         #训练模型\n",
    "        \n",
    "        train_data,test_data = train_test_split(data,test_size=0.3,random_state=2)\n",
    "        #得到y-true\n",
    "        y_true = test_data.iloc[:,0]\n",
    "        \n",
    "        \n",
    "        model_i.fit(train_data,estimator=BE,complete_samples_only=True,state_names=this_dict)\n",
    "        \n",
    "        #丢弃label获得\n",
    "        \n",
    "        test_data.drop(columns=\"label\",axis =1,inplace=True)\n",
    "      \n",
    "        #将预测的值从df转换为list形式\n",
    "        \n",
    "        #在predict的时候不知道什么会影响结果\n",
    "        y_pred = list(model_i.predict(test_data).iloc[:,0])\n",
    "       \n",
    "       #模型预测\n",
    "        acc[i] = accuracy_score(y_true,y_pred)\n",
    "        recall[i] = recall_score(y_true, y_pred)\n",
    "        auc_score[i] = roc_auc_score(y_true,y_pred)\n",
    "    return acc,recall,auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ea187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dag_score(dag,DB):\n",
    "    score =  []\n",
    "    \n",
    "    for data in DB:\n",
    "        #判断在每个网路之间分数\n",
    "        \n",
    "#                 k2 = K2Score(data)\n",
    "#         score.append(k2.score(dag))\n",
    "        bic = BicScore(data)\n",
    "        score.append(bic.score(dag))\n",
    "        \n",
    "        \n",
    "    acc,recall,auc_score = cross_validation(dag,DB,11)\n",
    "    \n",
    "    \n",
    "    print(acc,recall,auc_score)\n",
    "    score = np.array(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6038a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将所有的离散状态记录下来，以字典的方式\n",
    "state_names  ={\n",
    "    \"lable\":[0,1],\n",
    "    \"age\":[1,2,3,4,5,6,7,8],\n",
    "    \"sex\":[1,2],\n",
    "    \"race\":[1,2,3,4,5],\n",
    "    \"bmi\":[1,2,3,4],\n",
    "    \"temperature\":[1,2,3],\n",
    "    \"heartrate\":[1,2,3],\n",
    "    \"respiration\":[1,2,3],\n",
    "    \"SBP\":[1,2,3,4,5],\n",
    "    \"DBP\":[1,2,3,4,5],\n",
    "    \"paSystolic\":[1,2,3],\n",
    "    \"paDiastolic\":[1,2,3],\n",
    "    \"paMean\":[1,2,3],\n",
    "}\n",
    "LAB_list = []\n",
    "for i in range(1,61):\n",
    "    LAB_list.append((\"LAB\"+str(i),[1,2,3]))\n",
    "COM_list = []\n",
    "for i in range(1,12):\n",
    "    COM_list.append((\"COM\"+str(i),[0,1]))\n",
    "PRO_list = []\n",
    "for i in range(1,10):\n",
    "    COM_list.append((\"PRO\"+str(i),[0,1]))\n",
    "MED_list = []\n",
    "for i in range(1,55):\n",
    "    MED_list.append((\"MED\"+str(i),[0,1]))\n",
    "state_names.update(LAB_list)\n",
    "state_names.update(COM_list)\n",
    "state_names.update(PRO_list)\n",
    "state_names.update(MED_list)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587fa54c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in check.data(x) : variable PRO5 must have at least two levels.\n",
      "\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in check.data(x) : variable PRO5 must have at least two levels.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m初始化训练\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(client_num):\n\u001b[1;32m---> 35\u001b[0m             \u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;66;03m#计算初始性能，计算轮数的性能\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# #             print(\"各个客户端的初始性能\")\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#             acc,recall,auc_score = cross_validation(clients[i].model,client_data,clients[i].cid)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#             auc_list.append(acu_score)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#             recall_list.append(recall)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#             acc_list.append(acc)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m初始auc\u001b[39m\u001b[38;5;124m\"\u001b[39m,auc_list)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mclient.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m globalenv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_r_data\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m self_r_data\n\u001b[0;32m     24\u001b[0m r_script\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124mlibrary(bnlearn)\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124mfor(j in 1:ncol(self_r_data))\u001b[39m\u001b[38;5;124m{\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_script\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marc_strength_list \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(edges)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_edges \u001b[38;5;241m=\u001b[39m edges\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\robjects\\__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, string):\n\u001b[0;32m    458\u001b[0m     p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[1;32m--> 459\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\robjects\\functions.py:203\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m         v \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(k)\n\u001b[0;32m    202\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28msuper\u001b[39m(SignatureTranslatedFunction, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\robjects\\functions.py:126\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[1;32m--> 126\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(Function, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    127\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cdata_to_rinterface(cdata)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\rpy2\\rinterface.py:815\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m     res \u001b[38;5;241m=\u001b[39m rmemory\u001b[38;5;241m.\u001b[39mprotect(\n\u001b[0;32m    809\u001b[0m         openrlib\u001b[38;5;241m.\u001b[39mrlib\u001b[38;5;241m.\u001b[39mR_tryEval(\n\u001b[0;32m    810\u001b[0m             call_r,\n\u001b[0;32m    811\u001b[0m             call_context\u001b[38;5;241m.\u001b[39m__sexp__\u001b[38;5;241m.\u001b[39m_cdata,\n\u001b[0;32m    812\u001b[0m             error_occured)\n\u001b[0;32m    813\u001b[0m     )\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 815\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mRRuntimeError\u001b[0m: Error in check.data(x) : variable PRO5 must have at least two levels.\n"
     ]
    }
   ],
   "source": [
    "fuseDAG = DAG()\n",
    "global fuseDAG\n",
    "globalenv['sc'] = \"bic\"\n",
    "sth = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "pandas2ri.activate()\n",
    "# 结构训练\n",
    "train_round = 10\n",
    "round_num = 0\n",
    "client_num = 10\n",
    "clients = []\n",
    "for i in range(10):\n",
    "# 创建客户端，并且传入数据和结构学习模型\n",
    "    clients.append(client(client_data[i],i,sth))\n",
    "# 初始化服务器\n",
    "sever_1 = sever(6)\n",
    "global_edges_matrix = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "edges_strength_matrix = pd.DataFrame(np.zeros((len(feature),len(feature))),index = feature,columns=feature).astype(np.int16)\n",
    "while(round_num<train_round):\n",
    "    #利用二维矩阵传递边结构信息\n",
    "    auc_list = []\n",
    "    recall_list = []\n",
    "    acc_list = []\n",
    "    #开始训练\n",
    "    #重置矩阵,设置评分\n",
    "    global_edges_matrix.iloc[:,:] = 0\n",
    "    edges_strength_matrix.iloc[:,:] = 0\n",
    "    acc = 0\n",
    "    recall = 0\n",
    "    acu_score = 0\n",
    "    #第一轮，先本地客户端建立初始模型\n",
    "    if round_num == 0:\n",
    "        \n",
    "        print(\"初始化训练\")\n",
    "        for i in range(client_num):\n",
    "            clients[i].fit()\n",
    "\n",
    "            \n",
    "            #计算初始性能，计算轮数的性能\n",
    "# #             print(\"各个客户端的初始性能\")\n",
    "#             acc,recall,auc_score = cross_validation(clients[i].model,client_data,clients[i].cid)\n",
    "#             auc_list.append(acu_score)\n",
    "#             recall_list.append(recall)\n",
    "#             acc_list.append(acc)\n",
    "\n",
    "        print(\"初始auc\",auc_list)\n",
    "        print(\"初始recall\",recall_list)\n",
    "        print(\"初始acc\",acc_list)\n",
    "        auc_list = []\n",
    "        recall_list = []\n",
    "        acc_list = [] \n",
    "        \n",
    "    #get到每个客户端边强度的总和\n",
    "    arc_strength_list = []\n",
    "    arc_weight_list = []\n",
    "    #开始聚集客户端边的信息\n",
    "    for i in range(client_num):\n",
    "        #将客户端最好的模型边信息转换为矩阵形式\n",
    "        \n",
    "        global_edges_matrix+=to_matrix(clients[i].get_model().edges(),feature)\n",
    "        #将矩阵转换为列表形式，并strength按列合并数据\n",
    "        \n",
    "        arc_strength_list.append(np.float16(pd.DataFrame(clients[i].arc_strength_list)[\"strength\"].sum()))\n",
    "        \n",
    "#         edges_strength_matrix+=clients[i].edges_strength\n",
    "    #计算每个图像的权\n",
    "    sum_value = sum(arc_strength_list)\n",
    "\n",
    "    for  i in range(client_num):\n",
    "        arc_weight_list.append(arc_strength_list[i]/sum_value)\n",
    "    #汇集带权重的边的信息\n",
    "    for i in range(client_num):\n",
    "        edges_strength_matrix+=clients[i].edges_strength*arc_weight_list[i]*D_W[i]/len(clients[i].get_model().edges())\n",
    "    \n",
    "    #服务器开始汇集信息，并且将矩阵转换为Dag\n",
    "#     print(\"未过滤的融合矩阵\")\n",
    "#     for index in edges_matrix.index:\n",
    "#         for col in edges_matrix.columns:\n",
    "#             if edges_matrix.loc[index,col]!=0:\n",
    "#                 print(index,\"->\",col,\"[label=\",edges_matrix.loc[index,col],\"];\")\n",
    "    print(\"转换\")\n",
    "    fuseDAG = sever_1.Fd_caculate(edges_strength_matrix)\n",
    "    print(\"转换完毕\")\n",
    "    for j in fuseDAG.edges:\n",
    "        print(j[0],\"->\",j[1],\";\")\n",
    "    \n",
    "    \n",
    "    fuse_score = dag_score(fuseDAG,client_data)\n",
    "    print(fuse_score)\n",
    "    #得到fuseDAG之后，观察整个网络评分的变化\n",
    "    print(\"第\",round_num+1,\"次迭代\")\n",
    "    #输出融合模型\n",
    "#     print_dag(fuseDAG)\n",
    "    #更新客户端模型\n",
    "    print(\"更 新客户端\")\n",
    "    #更新客户端，就是将融合的DAG()，传给各个模型，并用bl从新训练\n",
    "    \n",
    "    for i in range(client_num):\n",
    "        print(i)\n",
    "        clients[i]. update_model(fuseDAG)\n",
    "    \n",
    "    round_num+=1\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dag(clients[8].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f0cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_list = []\n",
    "recall_list = []\n",
    "acc_list = []\n",
    "#测试更新后的性能\n",
    "for i in range(10):\n",
    "#     print(\"各个客户端的初始性能\")\n",
    "    acc,recall,auc_score = cross_validation(clients[i].model,client_data,clients[i].cid)\n",
    "    auc_list.append(auc_score)\n",
    "    recall_list.append(recall)\n",
    "    acc_list.append(acc)\n",
    "#     print(i)\n",
    "#     print_dag(clients[i].model)\n",
    "# print(\"更新auc\",auc_list)\n",
    "# print(\"更新recall\",recall_list)\n",
    "# print(\"更新acc\",acc_list)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list = np.atleast_2d(auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01b88013",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(10, 10, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m auc_result \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauc_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:331\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    326\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 331\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(values\u001b[38;5;241m.\u001b[39mdtype, dtype):\n\u001b[0;32m    334\u001b[0m     shape \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:591\u001b[0m, in \u001b[0;36m_prep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    589\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(10, 10, 1)"
     ]
    }
   ],
   "source": [
    "auc_result = pd.DataFrame(auc_list).round(4)   \n",
    "# recall_result = pd.DataFrame(recall_list).round(4)\n",
    "# acc_result = pd.DataFrame(acc_list).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e08751",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_result.to_csv(\"C:/Users/Administrator/Desktop/code/project_2/结果/auc.csv\")\n",
    "recall_result.to_csv(\"C:/Users/Administrator/Desktop/code/project_2/结果/recall.csv\")\n",
    "acc_result.to_csv(\"C:/Users/Administrator/Desktop/code/project_2/结果/acc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a04d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAB19 -> label ;\n",
      "COM1 -> label ;\n",
      "COM2 -> label ;\n",
      "COM3 -> label ;\n",
      "COM4 -> label ;\n",
      "COM5 -> label ;\n",
      "COM6 -> label ;\n",
      "COM7 -> label ;\n",
      "COM8 -> label ;\n",
      "COM9 -> label ;\n"
     ]
    }
   ],
   "source": [
    "for i  in fuseDAG.edges():\n",
    "    print(i[0],\"->\",i[1],\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dag(fuseDAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(client_num):\n",
    "    #将客户端最好的模型边信息转换为矩阵形式\n",
    "    edges_matrix+=to_matrix(clients[i].get_model().edges(),feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaebab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"第\",i)\n",
    "    print_dag(clients[i].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d38344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data420.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data142.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data122.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data435.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data390.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data227.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data195.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data243.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data403.csv\n",
      "C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data141.csv\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(hos_id,client_data):\n",
    "    path = \"C:/Users/Administrator/Desktop/代码/实验/fd/fd_data/data\"+str(i)+\".csv\"\n",
    "    print(path)\n",
    "    j.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d88ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gs(asia)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
